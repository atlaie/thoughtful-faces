{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from parse_logfile_newest import TextLog\n",
    "import pipeline_sLDS as pipln\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import BehavUtils as butils\n",
    "import glob\n",
    "from natsort import natsorted\n",
    "import time\n",
    "import reaction_time as reac\n",
    "from jax.config import config\n",
    "import os\n",
    "import acme\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "# Set seaborn plot style and ignore warnings\n",
    "sns.set_style('white')\n",
    "warnings.filterwarnings(action='ignore', message='Mean of empty slice')\n",
    "warnings.filterwarnings(action='ignore', message='Degrees of freedom <= 0 for slice')\n",
    "warnings.filterwarnings(action='ignore', message='All-NaN slice encountered')\n",
    "warnings.filterwarnings(action='ignore', message='RuntimeWarning: invalid value encountered in double_scalars')\n",
    "np.seterr(over='ignore')\n",
    "\n",
    "# Define the animal\n",
    "animal = 'mouse'\n",
    "\n",
    "# Load log, flash, face, and eye files\n",
    "with open('RawData/Mouse/files_logs_mouse_moreSes.txt') as f:\n",
    "    files_logs = [line.strip() for line in f.readlines()]\n",
    "with open('RawData/Mouse/files_flashes_mouse_moreSes.txt') as f:\n",
    "    files_flashes = [line.strip() for line in f.readlines()]\n",
    "with open('RawData/Mouse/files_face_mouse_moreSes_updated.txt') as f:\n",
    "    files_face = [line.strip() for line in f.readlines()]\n",
    "with open('RawData/Mouse/files_eye_mouse_moreSes_updated.txt') as f:\n",
    "    files_eye = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "# Define which column names to read from the face and eye files\n",
    "with open('RawData/Mouse/cols_nose_updated.txt') as f:\n",
    "    cols_nose = [line.strip() for line in f.readlines()]\n",
    "with open('RawData/Mouse/cols_whiskers_updated.txt') as f:\n",
    "    cols_whiskers = [line.strip() for line in f.readlines()]\n",
    "with open('RawData/Mouse/cols_eye.txt') as f:\n",
    "    cols_eye = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Define parameters for cross-validation, repetitions, and data splitting\n",
    "nWindows = 5\n",
    "nRepetitions = 5\n",
    "nSplits = 5\n",
    "btscv = butils.BlockingTimeSeriesSplit(n_splits=nSplits)\n",
    "shiftStim = -0.25\n",
    "winSize = 0.25\n",
    "internal_states = np.arange(2, 16)\n",
    "\n",
    "# Define how many partitions to use for Dask loading in the data.\n",
    "nPartitions = os.cpu_count() - 2\n",
    "\n",
    "# How many trials will Optuna optimize hyperparameters for?\n",
    "numTrials = 50\n",
    "\n",
    "# Clean up the cluster and set up a new cluster client\n",
    "acme.cluster_cleanup()\n",
    "client = acme.esi_cluster_setup(partition=\"8GBXS\", n_jobs=int(nSplits),\n",
    "                                n_jobs_startup=2, timeout=60000, interactive_wait=1)\n",
    "\n",
    "start1 = time.time()\n",
    "\n",
    "\n",
    "dat_train_list, dat_test_list, y_train_list, y_test_list = [], [], [], []\n",
    "concentration_list, stickiness_list, scores_cv_list = [], [], []\n",
    "for rr in range(len(files_logs)):\n",
    "    # Load flashes data\n",
    "    flashes = np.load(files_flashes[rr], allow_pickle=True)\n",
    "    # Parse event markers from log file\n",
    "    evt, newSamp, nPoints, t_final, idx_start, idx_stim, _ = butils.readLog(files_logs[rr], 'mouse')\n",
    "\n",
    "    # Process session data, reaction times, and rescale reaction times\n",
    "    sess_data = reac.sess_data_maker(files_logs[rr], animal, 3000)\n",
    "    r_time, _ = reac.reaction_time(sess_data, [5,10,15])\n",
    "    r_time[pd.isna(r_time)] = -1\n",
    "    r_time = r_time.astype(np.float64)\n",
    "    r_time = r_time / newSamp\n",
    "    r_time[r_time > 4] = 4\n",
    "\n",
    "    t_tmp = np.nan * np.ones(nPoints)\n",
    "    t_tmp[idx_start[:-1]] = flashes[:-1]\n",
    "    frames_dlc = pd.Series(t_tmp).interpolate(method=\"linear\").values\n",
    "    frames_dlc[np.isnan(frames_dlc)] = 0\n",
    "    frames_dlc = np.array(frames_dlc, dtype=int)\n",
    "\n",
    "    t_stim = np.unique(t_final[idx_stim])\n",
    "\n",
    "    dat_face = butils.daskLoadCSV(files_face[rr], cols_nose, nPartitions=nPartitions)\n",
    "    dat_whis = butils.daskLoadCSV(files_face[rr], cols_whiskers, nPartitions=nPartitions)\n",
    "    dat_eye = butils.daskLoadCSV(files_eye[rr], cols_eye, nPartitions=nPartitions)\n",
    "    \n",
    "    \n",
    "    nose_x_fin, nose_y_fin, _ = butils.dlcCalcs(dat_face, nPoints=frames_dlc.shape[0], doSize=0)\n",
    "    eye_x_fin, eye_y_fin, pupSize_t = butils.dlcCalcs(dat_eye, nPoints=frames_dlc.shape[0], doSize=1)\n",
    "    whisk_x_fin, whisk_y_fin, _ = butils.dlcCalcs(dat_whis, nPoints=frames_dlc.shape[0], doSize=0)\n",
    "\n",
    "    predVar = [eye_x_fin, eye_y_fin, nose_x_fin, nose_y_fin, whisk_x_fin, whisk_y_fin]\n",
    "    predictors = butils.preprocess_data(predVar,pupSize_t,eye_x_fin, eye_y_fin, t_final,idx_start,t_stim,animal,shiftStim,winSize)\n",
    "\n",
    "\n",
    "    if predictors.shape[0] > r_time.shape[0]:\n",
    "        predictors = predictors[:-1,:]\n",
    "    elif predictors.shape[0] < r_time.shape[0]:\n",
    "        r_time = r_time[:-1]\n",
    "    \n",
    "    size = int(len(r_time) * 0.8)\n",
    "    dat_train, dat_test, y_train, y_test = predictors[:size,:], predictors[size:,:], r_time[:size], r_time[size:]\n",
    "    estimator = BayesianRidge()\n",
    "\n",
    "    imp = IterativeImputer(estimator=estimator, random_state=42, max_iter = 100, sample_posterior = True, skip_complete = True)\n",
    "    dat_train = imp.fit_transform(dat_train)\n",
    "    dat_test = imp.transform(dat_test)\n",
    "    #dat_train, dat_test, y_train, y_test = butils.split_impute_scale(predictors, r_time, trainSize = 0.8, shift = 0)\n",
    "    y_train = y_train.reshape(-1,1)\n",
    "    y_test = y_test.reshape(-1,1)\n",
    "\n",
    "\n",
    "    dat_train_list.append(dat_train)\n",
    "    dat_test_list.append(dat_test)\n",
    "    y_train_list.append(y_train)\n",
    "    y_test_list.append(y_test)\n",
    "    filename = f'RawData/Mouse/Predictors_emissions_mouse_newDLC_test_session{rr}_nonScaled.npz'\n",
    "    np.savez(filename, predictors=dat_test, emissions=y_test)\n",
    "    \n",
    "dat_train_final = butils.pad_concatenate(dat_train_list,doEmissions = False, numPad = 20)\n",
    "y_train_final = butils.pad_concatenate(y_train_list,doEmissions = True, numPad = 20)\n",
    "np.savez('Predictors_emissions_mouse_newDLC_concat_train_20pad_nonScaled.npz', predictors = dat_train_final, emissions = y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import BehavUtils as butils\n",
    "import acme\n",
    "import time\n",
    "import reaction_time as reac\n",
    "import dask.dataframe as dd\n",
    "import os\n",
    "\n",
    "sns.set_style('white')\n",
    "warnings.filterwarnings(action='ignore', message='Mean of empty slice')\n",
    "warnings.filterwarnings(action='ignore', message='Degrees of freedom <= 0 for slice')\n",
    "warnings.filterwarnings(action='ignore', message='All-NaN slice encountered')\n",
    "warnings.filterwarnings(action='ignore', message='RuntimeWarning: invalid value encountered in double_scalars')\n",
    "np.seterr(over='ignore')\n",
    "\n",
    "animal = 'macaque'\n",
    "\n",
    "with open('RawData/Macaque/files_logs_macaque_moreSes.txt') as f:\n",
    "    files_logs = [line.strip() for line in f.readlines()]\n",
    "with open('RawData/Macaque/files_flashes_macaque_moreSes.txt') as f:\n",
    "    files_flashes = [line.strip() for line in f.readlines()]\n",
    "with open('RawData/Macaque/files_face_macaque_moreSes.txt') as f:\n",
    "    files_dlc = [line.strip() for line in f.readlines()]\n",
    "with open('RawData/Macaque/files_eye_macaque_moreSes.txt') as f:\n",
    "    files_eye = [line.strip() for line in f.readlines()]\n",
    "with open('RawData/Macaque/files_eyeNet_macaque_moreSes.txt') as f:\n",
    "    files_eyeNet = [line.strip() for line in f.readlines()]\n",
    "\n",
    "with open('RawData/Macaque/RelevantColumns_Larger.txt') as f:\n",
    "    relevant_cols = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "varNames = ['PupSize', 'EyeMov', 'Eye_x', 'Eye_y', 'rEar_x', 'rEar_y', 'lEar_x', 'lEar_y', \n",
    "            'rEyeBr_x', 'rEyeBr_y', 'lEyeBr_x', 'lEyeBr_y', 'nostrils_x', 'nostrils_y', \n",
    "            'uLip_x', 'uLip_y', 'lLip_x', 'lLip_y']\n",
    "\n",
    "# Define parameters for cross-validation, repetitions, and data splitting\n",
    "nWindows = 5\n",
    "nRepetitions = 5\n",
    "nSplits = 5\n",
    "btscv = butils.BlockingTimeSeriesSplit(n_splits=nSplits)\n",
    "shiftStim = -0.25\n",
    "winSize = 0.25\n",
    "internal_states = np.arange(2, 13)\n",
    "\n",
    "# Define how many partitions to use for Dask loading in the data.\n",
    "nPartitions = os.cpu_count() - 2\n",
    "\n",
    "# How many trials will Optuna optimize hyperparameters for?\n",
    "numTrials = 100\n",
    "# Clean up the cluster and set up a new cluster client\n",
    "acme.cluster_cleanup()\n",
    "client = acme.esi_cluster_setup(partition=\"8GBXS\", n_jobs=len(varNames),\n",
    "                                n_jobs_startup=2, timeout=60000, interactive_wait=1)\n",
    "\n",
    "subjects = []\n",
    "for ii in range(len(files_logs)):\n",
    "    subjects.append(files_logs[ii].split('/')[5])\n",
    "uniq_subj = np.unique(subjects)\n",
    "start1 = time.time()\n",
    "\n",
    "\n",
    "dat_train_list, dat_test_list, y_train_list, y_test_list = [], [], [], []\n",
    "concentration_list, stickiness_list, scores_cv_list = [], [], []\n",
    "\n",
    "for rr in range(len(files_logs)):\n",
    "\n",
    "    r_earCols, l_earCols, r_eyeBrowCols, l_eyeBrowCols = [], [], [], []\n",
    "    nostrilsCols, u_lipCols, l_lipCols = [], [], []\n",
    "\n",
    "    flashes = np.load(files_flashes[rr], allow_pickle=True)\n",
    "    # Parse event markers from log file\n",
    "    evt, newSamp, nPoints, t_final, idx_start, idx_stim, _ = butils.readLog(files_logs[rr], animal)\n",
    "\n",
    "    # Process session data, reaction times, and rescale reaction times\n",
    "    sess_data = reac.sess_data_maker(files_logs[rr], animal, 3000)\n",
    "    r_time, _ = reac.reaction_time(sess_data, [5,10,15])\n",
    "    r_time[pd.isna(r_time)] = -1\n",
    "    r_time = r_time.astype(np.float64)\n",
    "    r_time = r_time / newSamp\n",
    "    r_time[r_time > 4] = 4\n",
    "\n",
    "    dat_eyeNet = pd.read_csv(files_eyeNet[rr])\n",
    "    times_eyeNet = dat_eyeNet['time_cpu'].values\n",
    "    evts_eyeNet = dat_eyeNet['data'].values\n",
    "    random_numbers = evts_eyeNet[evts_eyeNet>30000]\n",
    "\n",
    "    start = butils.search_sequence(evts_eyeNet, evt[evt>30000])[-1]+1\n",
    "    end = butils.search_sequence(evts_eyeNet, evts_eyeNet[evts_eyeNet>30000][-3:])[0]-1\n",
    "    t_tmp = np.nan * np.ones(nPoints)\n",
    "    t_tmp[idx_start[:-1]] = flashes[:-1]\n",
    "    frames_dlc = pd.Series(t_tmp).interpolate(method=\"linear\").values\n",
    "    frames_dlc[np.isnan(frames_dlc)] = 0\n",
    "    frames_dlc = np.array(frames_dlc, dtype=int)\n",
    "\n",
    "    t_stim = np.unique(t_final[idx_stim])\n",
    "\n",
    "    dat_eye = pd.read_csv(files_eye[rr])\n",
    "    t_tmp = dat_eye['time'].values\n",
    "    fast_locs = np.searchsorted(t_tmp, [times_eyeNet[start], times_eyeNet[end]])\n",
    "    t_eye = t_tmp[fast_locs[0]:fast_locs[-1]]\n",
    "\n",
    "    df_train = dd.read_csv(files_dlc[rr], usecols = relevant_cols, header = 1, low_memory = False)\n",
    "\n",
    "    df_train=df_train.compute()\n",
    "    df_train.drop(0, inplace=True)\n",
    "    dask_dat_dlc = dd.from_pandas(df_train, npartitions=nRepetitions)\n",
    "    for col in dask_dat_dlc.columns:\n",
    "        dask_dat_dlc[col] = dd.to_numeric(dask_dat_dlc[col])\n",
    "\n",
    "    for col in dask_dat_dlc.columns:\n",
    "        if 'RightEar' in col:\n",
    "            r_earCols.append(col)\n",
    "        elif 'LeftEar' in col:\n",
    "            l_earCols.append(col)\n",
    "        elif 'RightBrow' in col:\n",
    "            r_eyeBrowCols.append(col)\n",
    "        elif 'LeftBrow' in col:\n",
    "            l_eyeBrowCols.append(col) \n",
    "\n",
    "        elif 'Nostrils' in col:\n",
    "            nostrilsCols.append(col)\n",
    "        elif 'UpperLip' in col:\n",
    "            u_lipCols.append(col)\n",
    "        elif 'LowerLip' in col:\n",
    "            l_lipCols.append(col)\n",
    "\n",
    "    dat_dlc = dask_dat_dlc.compute()\n",
    "    rEar_x_fin, rEar_y_fin, _ = butils.dlcCalcs(dat_dlc[r_earCols], nPoints = frames_dlc.shape[0], doSize = 0)\n",
    "    lEar_x_fin, lEar_y_fin, _  = butils.dlcCalcs(dat_dlc[l_earCols], nPoints = frames_dlc.shape[0], doSize = 0)\n",
    "    rEyeBr_x_fin, rEyeBr_y_fin, _  = butils.dlcCalcs(dat_dlc[r_eyeBrowCols], nPoints = frames_dlc.shape[0], doSize = 0)\n",
    "    lEyeBr_x_fin, lEyeBr_y_fin, _  = butils.dlcCalcs(dat_dlc[l_eyeBrowCols], nPoints = frames_dlc.shape[0], doSize = 0)\n",
    "\n",
    "    eye_x, eye_y, pupSize = butils.eyeCalcs(files_eye[rr], t_eye.shape[0])\n",
    "\n",
    "    nostrils_x_fin, nostrils_y_fin, _ = butils.dlcCalcs(dat_dlc[nostrilsCols], nPoints = frames_dlc.shape[0], doSize = 0)\n",
    "    uLip_x_fin, uLip_y_fin, _  = butils.dlcCalcs(dat_dlc[u_lipCols], nPoints = frames_dlc.shape[0], doSize = 0)\n",
    "    lLip_x_fin, lLip_y_fin, _  = butils.dlcCalcs(dat_dlc[l_lipCols], nPoints = frames_dlc.shape[0], doSize = 0)\n",
    "\n",
    "    predVar = [eye_x, eye_y, rEar_x_fin, rEar_y_fin, lEar_x_fin, lEar_y_fin, rEyeBr_x_fin, rEyeBr_y_fin, lEyeBr_x_fin, lEyeBr_y_fin,\n",
    "              nostrils_x_fin, nostrils_y_fin, uLip_x_fin, uLip_y_fin, lLip_x_fin, lLip_y_fin]\n",
    "    predictors = butils.preprocess_data(predVar,pupSize,eye_x, eye_y,t_final,idx_start,t_stim,animal,shiftStim,winSize,t_eye)\n",
    "\n",
    "    if predictors.shape[0] > r_time.shape[0]:\n",
    "        predictors = predictors[:-1,:]\n",
    "    elif predictors.shape[0] < r_time.shape[0]:\n",
    "        r_time = r_time[:-1]\n",
    "\n",
    "    dat_train, dat_test, y_train, y_test = butils.split_impute_scale(predictors, r_time, trainSize = 0.8, shift = 0)\n",
    "    y_train = y_train.reshape(-1,1)\n",
    "    y_test = y_test.reshape(-1,1)\n",
    "\n",
    "\n",
    "    dat_train_list.append(dat_train)\n",
    "    dat_test_list.append(dat_test)\n",
    "    y_train_list.append(y_train)\n",
    "    y_test_list.append(y_test)\n",
    "    filename = f'RawData/Macaque/Predictors_emissions_macaque_test_session{rr}.npz'\n",
    "    np.savez(filename, predictors=dat_test, emissions=y_test)\n",
    "    print('Session '+str(rr)+' is done.')\n",
    "\n",
    "dat_train_final_macaque = butils.pad_concatenate(dat_train_list,doEmissions = False, numPad = 50)\n",
    "y_train_final_macaque = butils.pad_concatenate(y_train_list,doEmissions = True, numPad = 50)\n",
    "dat_test_final_macaque = butils.pad_concatenate(dat_test_list,doEmissions = False, numPad = 50)\n",
    "y_test_final_macaque = butils.pad_concatenate(y_test_list,doEmissions = True, numPad = 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cluster-GLMHMM3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
